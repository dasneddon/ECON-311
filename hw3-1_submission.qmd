---
title: "Homework 3.1"
author: "David Sneddon"
institute: "Old Dominion University"
format: 
  html:
    theme: lux # Check here for more themes: https://quarto.org/docs/output-formats/html-themes.html
    code-tools: true
    code-fold: true
    code-summary: "Code"
    code-copy: hover
    link-external-newwindow: true
    tbl-cap-location: top
    fig-cap-location: bottom

self-contained: true
editor: source
---

```{r setup, include=FALSE}
# DO NOT EDIT THIS

knitr::opts_chunk$set(fig.align = 'center')
knitr::opts_chunk$set(out.width = '90%')
knitr::opts_chunk$set(results = 'hold')
knitr::opts_chunk$set(fig.show = 'hold')
knitr::opts_chunk$set(error = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
par(mar = c(4.1, 4.1, 1.1, 4.1))

hooks = knitr::knit_hooks$get()
hook_foldable = function(type) {
  force(type)
  function(x, options) {
    res = hooks[[type]](x, options)
    
    if (is.na(as.logical(options[[paste0("fold.", type)]]))) {
      
      res
    } else if (isFALSE(as.logical(options[[paste0("fold.", type)]]))){
      
      # return(res)
      
      paste0(
      "<details open><summary>", gsub("^p", "P", gsub("^o", "O", type)), "</summary>\n\n",
      res,
      "\n\n</details>"
      )
    } else {
      
      paste0(
      "<details><summary>", gsub("^p", "P", gsub("^o", "O", type)), "</summary>\n\n",
      res,
      "\n\n</details>"
      )
    }
  }
}

knitr::knit_hooks$set(
  output = hook_foldable("output"),
  plot = hook_foldable("plot")
)
knitr::opts_chunk$set(fold.output=TRUE)
knitr::opts_chunk$set(fold.plot=TRUE)

Q <- 0
```

## Question `r Q <- Q+1; Q`

```{r include=FALSE}
q <- 0
```

For this question, you are going to analyze tipping culture. Consider these data ([data](https://vincentarelbundock.github.io/Rdatasets/csv/reshape2/tips.csv); [documentation](https://vincentarelbundock.github.io/Rdatasets/doc/reshape2/tips.html)) on tips received by a single waiter over a period of a few months.

`r q <- q+1; letters[q]`. Read in the data into R. (**2 Points**)

```{r}
tips <- read.csv("https://vincentarelbundock.github.io/Rdatasets/csv/reshape2/tips.csv")
```

`r q <- q+1; letters[q]`. Create a table of summary statistics for `total_bill` and `tip`. (**2 Points**)

```{r, warning=FALSE, message=FALSE}
library(modelsummary)
options("modelsummary_factory_default" = "kableExtra")
title <- "Tipping Data - Summary Statistics"
frmla <- (`Total Bill` = total_bill) + (`Tip` = tip)  ~ (`N` = length) + Mean + (`St. Dev.` = sd) + (`Min` = min) + (`Max` = max)
datasummary(frmla, data = tips, title = title, fmt = fmt_significant(2))

```

`r q <- q+1; letters[q]`. Write down an econometric model (i.e. use $\beta_0$ and $\beta_1$) that explains tip amount based on the total bill amount. (**2 Points**)

$$
\hat{Y}_{Tip} = \hat{\beta_0} + \hat{\beta_1}X_{Bill}
$$
`r q <- q+1; letters[q]`. The rule-of-thumb for tipping is to give 18% of the total bill. If this rule of thumb were followed, what would we expect for values of $\beta_0$ and $\beta_1$? (**4 Points**)

We would expect $\beta_0 = 0$ and $\beta_1 = 0.18$.

`r q <- q+1; letters[q]`. Plot `total_bill` vs `tip`. Make the figure presentable with labeled axes, colored points (with some opacity), etc. (**2 Points**)

```{r}
library(scales)
plot(x = tips$total_bill, 
     y = tips$tip,
     main = "Total Bill vs Tip",
     xlab = "Total Bill",
     ylab = "Tip",
     las = 1,
     type = "p",
     pch = 20,
     col = alpha("blue",0.2)
)
```

`r q <- q+1; letters[q]`. Estimate the parameters in the model.  Interpret the value of each coefficient in words. (**2 Points**)

```{r}
tipmodel <- lm(formula = tip ~ total_bill,
               data = tips)
tipmodel
```

$\hat{\beta_0} = 0.9203$ is the y-intercept of the model. This doesn't provide much information, as it is unlikely that a tip would be left with a $X_{bill}$ of $0$. However, with an $X_{bill}$ of $0$ the model predicts a tip of $\$0.9203$.

$\hat{\beta_1} = 0.1050$ implies that for every addtional $\$1$ there is a $\$0.1050$ increase in the tip or the average tip is around $10.5\%$.

`r q <- q+1; letters[q]`. Re-create the plot, but include the regression line *and* the rule-of-thumb for tipping.  Make each line a different color and include a legend.  Discuss how people tip in reality compared to the rule-of-thumb. (**6 Points**)

```{r}
plot(x = tips$total_bill, 
     y = tips$tip,
     main = "Total Bill vs Tip",
     xlab = "Total Bill ($)",
     ylab = "Tip ($)",
     las = 1,
     type = "p",
     pch = 20,
     col = alpha("black", 0.25),
     xlim = c(0, max(tips$total_bill)+1),
     ylim = c(0, max(tips$tip)+1),
     xaxs = "i",
     yaxs = "i")
abline(tipmodel,
       lty  = 1,
       col ="red")
abline(a = 0,
       b = 0.18,
       lty  = 1,
       col ="blue")
legend("bottomright",
       lty = 1,
       bty = "n",
       legend = c("18% Tip","Model Prediction"),
       col = c("blue","red"),
       cex = 0.75)
```

It appears the trend is that people tip far less than the rule-of-thumb.


## Question `r Q <- Q+1; Q`

```{r include=FALSE}
q <- 0
```

The American Housing Survey (AHS) collects information about individual dwelling choices.  These data ([data](https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/MetroCommutes.csv); [documentation](https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/MetroCommutes.html)), which are a subset of the 2007 AHS, contain information on distances and times individuals travel for their commutes to work. (**2 Points**)

`r q <- q+1; letters[q]`. Read the data into R.

```{r}
metrocommutes <- read.csv("https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/MetroCommutes.csv")
```

`r q <- q+1; letters[q]`. Estimate two models of commute time given commute distance. First, estimate a level-level model. Second, estimate a log-log model. Display the coefficients in a table. (**4 Points**)

```{r}
levelcommute <- lm(formula = Time ~ Distance,
                   data = metrocommutes)
asinhcommute <- lm(formula = asinh(Time) ~ asinh(Distance),
                 data = metrocommutes)
regz <- list(`Level - Level` = levelcommute,
             `Log - Log (using arsinh)` = asinhcommute)
coefz <- list("Distance" = "Distance",
              "asinh(Distance)" = "arsinh(Distance)",
              "(Intercept)" = "Constant")
gofz <- c("nobs", "r.squared")

modelsummary(regz,
             title = "Effect of Distance on Commute",
             estimate = "{estimate}{stars}",
             coef_map = coefz,
             gof_map = gofz)

```

`r q <- q+1; letters[q]`. Suppose you are a commuter who wants to live as far as possible from their job which is in the middle of a city center (and thus subject to pollution, crime, noise, and everything else you don't like). However, you also don't like commuting; each minute in traffic is torture to you. If you are willing to spend 30 minutes in traffic, how far from work, in miles, should you live? Use the parameters from the level-level model to inform your decision. (**2 Points**)

Given $Y_{Time}=30$ and $\hat{Y}_{Time} = 9.705 + 1.145X_{Dist}$.\
We want to find $X_{Dist} : \hat{Y}_{Time} = 30$ so we can solve for $X_{Dist}$ and get $X_{Dist} = 17.7249$

`r q <- q+1; letters[q]`. Estimate the level-level model for each city in the data.  Display the coefficients in a single table. (**4 Points**)

```{r}

citiez <- unique(metrocommutes$City)
ll_cities <- list()
level_level <- function (cityframe, city) {
  cityframe <- as.data.frame(cityframe)
  colnames(cityframe) <- colnames(metrocommutes)
   return (lm(formula = Time ~ Distance,
              data = cityframe,
              subset = cityframe$City == city
              ))

}

for (x in unique(metrocommutes$City)){
  ll_cities <- append(ll_cities, list(level_level(metrocommutes, x)))
}
names(ll_cities) <- citiez
modelsummary(ll_cities,
             title = "Effect of Distance on Commute - by City - level-level",
             estimate = "{estimate}{stars}",
             coef_map = coefz,
             gof_map = gofz)
```

`r q <- q+1; letters[q]`. Compare the coefficients for Boston, the highest density city in the sample, to Houston, the lowest density city in the sample.^[Persons (in 2016) per Square Mile: Boston (13,943), Houston (3,842), Minneapolis (7,664), and Washington (11,158).] (**2 Points**)

Boston shows a slightly lower effect of distance on time than Houston.

`r q <- q+1; letters[q]`. Following from the previous question, why do you think a city's density appears to be related to its $R^2$ in the models above? (**2 Points**)

A city's density appears to have an effect on commute time. The greater the density, the greater the effect on the single variable regression. The model would be more accurate with density as a regressor.



## Question `r Q <- Q+1; Q`

```{r include=FALSE}
q <- 0
```

Infant birth weight is an often used measure in health economics, serving as a vital indicator of an infant's immediate and long-term health prospects. One of the key determinants of birth weight is the infant's gestation period, or the time spent in utero. Use these data ([data](https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/Gestation.csv); [documentation](https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/Gestation.html)) records of births from 1961 and 1962 to answer the following questions.

`r q <- q+1; letters[q]`. Read in the data. Convert birth weight to pounds and gestation to weeks, both as new variables. Use the `floor()` function to round gestation down to the nearest whole week. (**2 Points**)

```{r}
birth_data <- read.csv("https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/Gestation.csv")
birth_data$gestation_weeks <- floor(birth_data$gestation/7)
birth_data$wt_lb <- birth_data$wt/16
```

`r q <- q+1; letters[q]`. Plot the distribution of gestation (in weeks). Be sure to label the axes, etc. What are some things you notice about the distribution? (**3 Points**)

```{r}
plot(table(birth_data$gestation_weeks[!is.na(birth_data$gestation_weeks)]),
     main = "Distribution of Gestation Time",
     xlab = "Gestation in Weeks",
     ylab = "Frequency",
     las = 1)
```

This appears to approximate a normal distribution with a median at around 39-40 weeks.

`r q <- q+1; letters[q]`. Create a visualization of average birth weight by weeks of gestation. What are some things you notice about the figure? (**3 Points**)

```{r}
plot(birth_data$gestation_weeks[!is.na(birth_data$gestation_weeks) & !is.na(birth_data$wt_lb)],
     birth_data$wt_lb[!is.na(birth_data$gestation_weeks) & !is.na(birth_data$wt_lb)],
     pch = 16,
     cex = 0.75,
     col = alpha("blue", 0.25),
     main = "Birth Weight by Weeks of Gestation",
     xlab = "Weeks of Gestation",
     ylab = "Birth Weight in Pounds",
     las = 1)
```

Most babies in the sample are born between 38-41 weeks and weigh between 6-8 pounds and there appears to be a positive correlation between gestation time and birth weight.

`r q <- q+1; letters[q]`. Estimate models to explain birth weight in pounds using gestation in weeks. The first model should be level-level and the second model should be log-level. You should eliminate any outliers you might have identified from the data. Present the coefficients in a table. (**2 Points**)

```{r}
levlev <- as.formula(wt_lb ~ gestation_weeks)
loglog <- as.formula(log(wt_lb) ~ log(gestation_weeks))
ol_rm <- function (datah, formulah){
  reg <- lm(formulah, datah)
  cookz <- cooks.distance(reg)
  thresh <- 4 / (nrow(datah) - length(coef(reg)) - 1)
  outz <- cookz > thresh
  return(datah[!outz,])
  
}

reg_levlev <- lm(formula = levlev,
                 data = birth_data)
reg_loglog <- lm(formula = loglog,
                 data = birth_data)
reg_levlev_c <- lm(formula = levlev,
                 data = ol_rm(birth_data,levlev))
reg_loglog_c <- lm(formula = loglog,
                 data = ol_rm(birth_data,loglog))
regz <- list(reg_levlev,reg_loglog,reg_levlev_c,reg_loglog_c)
names(regz) <- c("Level-Level", "Log-Log", "Level-Level-Clean", "Log-Log-Clean")
modelsummary(regz,
             gof_map = gofz)

```

`r q <- q+1; letters[q]`. Interpret each coefficient from each model in words. (**4 Points**)

Each week of gestation results in a 0.205 lb. increase in birth weight and a 1% increase in gestation time results in a 1.129% increase in birth weight.






